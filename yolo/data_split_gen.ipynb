{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"/mnt/ssd2/xin/repo/DART/Liebherr_Product\")\n",
    "repo_dir = Path(\"/mnt/ssd2/xin/repo/DART/diversification/dreambooth\")\n",
    "\n",
    "generated_data_dir = repo_dir / \"generated_data\"\n",
    "\n",
    "# Define the images directory and duplicates directory using Path objects\n",
    "image_dir = dataset_dir / \"images\"\n",
    "meta_dir = dataset_dir / \"metadata\"\n",
    "\n",
    "label_gen_dir = dataset_dir / \"labels_gen\"\n",
    "label_orig_dir = dataset_dir / \"labels\"\n",
    "label_background_dir = dataset_dir / \"labels_background\"\n",
    "\n",
    "label_dir = dataset_dir / \"labels\"\n",
    "yolo_dir = dataset_dir / \"yolo\"\n",
    "\n",
    "label_all_dir = dataset_dir / \"labels_all\"\n",
    "yolo_all_dir = dataset_dir / \"yolo_all\"\n",
    "\n",
    "\n",
    "# List all objects in the image directory\n",
    "objs = sorted([obj.name for obj in image_dir.iterdir() if obj.is_dir()])\n",
    "\n",
    "with open(meta_dir / \"id_to_name.json\", \"r\") as f:\n",
    "    id_to_name = json.load(f)\n",
    "with open(meta_dir / \"id_to_name_gen.json\", \"r\") as f:\n",
    "    id_to_name_gen = json.load(f)\n",
    "with open(meta_dir / \"classes.json\", \"r\") as f:\n",
    "    class_name_to_id = json.load(f)\n",
    "    class_id_to_name = {v: k for k, v in class_name_to_id.items()}\n",
    "with open(meta_dir / \"near_duplicates.json\", \"r\") as f:\n",
    "    near_duplicates = json.load(f)\n",
    "\n",
    "with open(label_all_dir / \"labels_nms.json\", \"r\") as f:\n",
    "    labels_nms_all = json.load(f)\n",
    "with open(label_orig_dir / \"labels_nms.json\", \"r\") as f:\n",
    "    labels_nms_orig = json.load(f)\n",
    "with open(label_gen_dir / \"labels_nms.json\", \"r\") as f:\n",
    "    labels_nms_gen = json.load(f)\n",
    "with open(label_background_dir / \"labels_nms.json\", \"r\") as f:\n",
    "    labels_nms_background = json.load(f)\n",
    "\n",
    "with open(label_gen_dir / \"stats_obj_nms.json\", \"r\") as f:\n",
    "    stats_obj_nms_gen = json.load(f)\n",
    "\n",
    "with open(label_all_dir / \"no_ann.json\", \"r\") as f:\n",
    "    no_ann_all = json.load(f)\n",
    "with open(label_orig_dir / \"no_ann.json\", \"r\") as f:\n",
    "    no_ann_orig = json.load(f)\n",
    "with open(label_gen_dir / \"no_ann.json\", \"r\") as f:\n",
    "    no_ann_gen = json.load(f)\n",
    "with open(label_background_dir / \"no_ann.json\", \"r\") as f:\n",
    "    no_ann_background = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance obj-wise filter\n",
    "a list of objcts with MAP < 0.9 for training with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articulated dump truck',\n",
       " 'bulldozer',\n",
       " 'combined piling and drilling rig',\n",
       " 'crawler crane',\n",
       " 'crawler loader',\n",
       " 'duty cycle crane',\n",
       " 'gantry crane',\n",
       " 'log loader',\n",
       " 'maritime crane',\n",
       " 'material handling machine',\n",
       " 'mining bulldozer',\n",
       " 'mining truck',\n",
       " 'mobile crane',\n",
       " 'pipelayer',\n",
       " 'pontoon excavator',\n",
       " 'reachstacker',\n",
       " 'telescopic handler',\n",
       " 'tower crane']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_obj_ids = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
    "include_objs = [class_id_to_name[id] for id in include_obj_ids]\n",
    "include_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt-wise filter\n",
    "a list of prompts that are not suitable for training with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articulated dump truck: 0\n",
      "bulldozer: 0\n",
      "combined piling and drilling rig: 0\n",
      "crawler crane: 0\n",
      "crawler excavator: 0\n",
      "crawler loader: 0\n",
      "duty cycle crane: 1\n",
      "gantry crane: 15\n",
      "log loader: 0\n",
      "maritime crane: 16\n",
      "material handling machine: 0\n",
      "mining bulldozer: 9\n",
      "mining excavator: 9\n",
      "mining truck: 9\n",
      "mobile crane: 0\n",
      "pipelayer: 0\n",
      "pontoon excavator: 16\n",
      "reachstacker: 0\n",
      "telescopic handler: 0\n",
      "tower crane: 1\n",
      "truck mixer: 0\n",
      "wheel excavator: 0\n",
      "wheel loader: 0\n"
     ]
    }
   ],
   "source": [
    "unsuitable_prompts = {\n",
    "    \"articulated dump truck\": [],\n",
    "    \"bulldozer\": [],\n",
    "    \"combined piling and drilling rig\": [],\n",
    "    \"crawler crane\": [],\n",
    "    \"crawler excavator\": [],\n",
    "    \"crawler loader\": [],\n",
    "    \"duty cycle crane\": [\"underground_construction\"],\n",
    "    \"gantry crane\": [\n",
    "        \"underground_construction\",\n",
    "        \"mining_site\",\n",
    "        \"highway_construction\",\n",
    "        \"city_street\",\n",
    "        \"urban_renewal\",\n",
    "        \"urban_demolition\",\n",
    "        \"urban_parking_lot\",\n",
    "        \"rural_area\",\n",
    "        \"forest_construction\",\n",
    "        \"suburban_construction\",\n",
    "        \"railway_construction\",\n",
    "        \"solar_farm_construction\",\n",
    "        \"skyscraper_construction\",\n",
    "        \"wind_farm_construction\",\n",
    "        \"multiple_machines_highway\",\n",
    "    ],\n",
    "    \"log loader\": [],\n",
    "    \"maritime crane\": [\n",
    "        \"underground_construction\",\n",
    "        \"mining_site\",\n",
    "        \"highway_construction\",\n",
    "        \"city_street\",\n",
    "        \"urban_renewal\",\n",
    "        \"urban_demolition\",\n",
    "        \"urban_parking_lot\",\n",
    "        \"rural_area\",\n",
    "        \"forest_construction\",\n",
    "        \"suburban_construction\",\n",
    "        \"railway_construction\",\n",
    "        \"solar_farm_construction\",\n",
    "        \"skyscraper_construction\",\n",
    "        \"wind_farm_construction\",\n",
    "        \"multiple_machines_city_street\",\n",
    "        \"multiple_machines_highway\",\n",
    "    ],\n",
    "    \"material handling machine\": [],\n",
    "    \"mining bulldozer\": [\n",
    "        \"city_street\",\n",
    "        \"highway_construction\",\n",
    "        \"urban_renewal\",\n",
    "        \"urban_demolition\",\n",
    "        \"urban_parking_lot\",\n",
    "        \"suburban_construction\",\n",
    "        \"skyscraper_construction\",\n",
    "        \"multiple_machines_city_street\",\n",
    "        \"multiple_machines_highway\",\n",
    "    ],\n",
    "    \"mining excavator\": [\n",
    "        \"city_street\",\n",
    "        \"highway_construction\",\n",
    "        \"urban_renewal\",\n",
    "        \"urban_demolition\",\n",
    "        \"urban_parking_lot\",\n",
    "        \"suburban_construction\",\n",
    "        \"skyscraper_construction\",\n",
    "        \"multiple_machines_city_street\",\n",
    "        \"multiple_machines_highway\",\n",
    "    ],\n",
    "    \"mining truck\": [\n",
    "        \"city_street\",\n",
    "        \"highway_construction\",\n",
    "        \"urban_renewal\",\n",
    "        \"urban_demolition\",\n",
    "        \"urban_parking_lot\",\n",
    "        \"suburban_construction\",\n",
    "        \"skyscraper_construction\",\n",
    "        \"multiple_machines_city_street\",\n",
    "        \"multiple_machines_highway\",\n",
    "    ],\n",
    "    \"mobile crane\": [],\n",
    "    \"pipelayer\": [],\n",
    "    \"pontoon excavator\": [\n",
    "        \"underground_construction\",\n",
    "        \"mining_site\",\n",
    "        \"highway_construction\",\n",
    "        \"city_street\",\n",
    "        \"urban_renewal\",\n",
    "        \"urban_demolition\",\n",
    "        \"urban_parking_lot\",\n",
    "        \"rural_area\",\n",
    "        \"forest_construction\",\n",
    "        \"suburban_construction\",\n",
    "        \"railway_construction\",\n",
    "        \"solar_farm_construction\",\n",
    "        \"skyscraper_construction\",\n",
    "        \"wind_farm_construction\",\n",
    "        \"multiple_machines_city_street\",\n",
    "        \"multiple_machines_highway\",\n",
    "    ],\n",
    "    \"reachstacker\": [],\n",
    "    \"telescopic handler\": [],\n",
    "    \"tower crane\": [\"underground_construction\"],\n",
    "    \"truck mixer\": [],\n",
    "    \"wheel excavator\": [],\n",
    "    \"wheel loader\": [],\n",
    "}\n",
    "for obj, ls in unsuitable_prompts.items():\n",
    "    print(f\"{obj}: {len(ls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMM image-wise filter\n",
    "a list of images not approved by lmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d14520', 'd18678', 'd63579', 'd43780', 'd45061']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(repo_dir / \"no_lmm.json\", \"r\") as f:\n",
    "    no_lmm = json.load(f)\n",
    "no_lmm[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "\n",
    "# the test text files that need to be deduplicated\n",
    "txt_names = [\n",
    "    \"test.txt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter\n",
    "with special prompts\n",
    "\n",
    "all three filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'articulated dump truck': 957,\n",
       " 'bulldozer': 3805,\n",
       " 'combined piling and drilling rig': 2877,\n",
       " 'crawler crane': 3834,\n",
       " 'crawler excavator': 0,\n",
       " 'crawler loader': 1885,\n",
       " 'duty cycle crane': 2785,\n",
       " 'gantry crane': 2460,\n",
       " 'log loader': 4796,\n",
       " 'maritime crane': 2999,\n",
       " 'material handling machine': 3838,\n",
       " 'mining bulldozer': 3752,\n",
       " 'mining excavator': 0,\n",
       " 'mining truck': 1920,\n",
       " 'mobile crane': 1816,\n",
       " 'pipelayer': 1401,\n",
       " 'pontoon excavator': 1629,\n",
       " 'reachstacker': 931,\n",
       " 'telescopic handler': 4775,\n",
       " 'tower crane': 2680,\n",
       " 'truck mixer': 0,\n",
       " 'wheel excavator': 0,\n",
       " 'wheel loader': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter 0: get rid of the images with no annotations\n",
    "ids_gen = set(labels_nms_gen.keys()) - set(no_ann_gen)\n",
    "ids_orig = set(labels_nms_orig.keys()) - set(no_ann_orig)\n",
    "ids_background = set(labels_nms_background.keys()) - set(no_ann_background)\n",
    "\n",
    "quota = {obj: 0 for obj in objs}\n",
    "for id in ids_gen:\n",
    "    obj = id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \")\n",
    "    orig_stem = id_to_name_gen[id + \".jpg\"].split(\"/\")[-1]\n",
    "    # performance filter\n",
    "    if obj not in include_objs:\n",
    "        continue\n",
    "    # prompt filter\n",
    "    no_promopt_keys = unsuitable_prompts[obj]\n",
    "    if any([key in orig_stem for key in no_promopt_keys]):\n",
    "        continue\n",
    "    # lmm filter\n",
    "    if id in no_lmm:\n",
    "        continue\n",
    "    quota[obj] += 1\n",
    "quota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without multiplyer\n",
    "\n",
    "corrsponds to generated-to-original data ratio 4:1 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for test.txt\n",
      "training dataset size: 61444 images\n",
      "from which 49140 images are generated data\n"
     ]
    }
   ],
   "source": [
    "yolo_filter_dir = dataset_dir / \"yolo_filter\"  # TODO: change the name\n",
    "yolo_filter_dir.mkdir(exist_ok=True)\n",
    "os.symlink(image_dir, yolo_filter_dir / \"images\", target_is_directory=True)\n",
    "os.symlink(\n",
    "    generated_data_dir, yolo_filter_dir / \"generated_data\", target_is_directory=True\n",
    ")\n",
    "os.symlink(\n",
    "    yolo_all_dir / \"labels\", yolo_filter_dir / \"labels\", target_is_directory=True\n",
    ")\n",
    "\n",
    "# training set composition:\n",
    "# rest of the original data, all of the background data, and {multiplier} percentatge of the generated data\n",
    "\n",
    "# for test_txt in yolo_dir.iterdir():\n",
    "for txt_name in txt_names:\n",
    "    test_txt = yolo_dir / txt_name\n",
    "\n",
    "    with open(test_txt, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    test_ids_orig = set([line.split(\"/\")[-1].split(\".\")[0] for line in lines])\n",
    "    # TODO: do not consider val for now\n",
    "    train_ids_orig = ids_orig - test_ids_orig\n",
    "    train_list = []\n",
    "    # add rest of the original data\n",
    "    for id in train_ids_orig:\n",
    "        obj = id_to_name[id + \".jpg\"].split(\"/\")[0]\n",
    "        train_list.append(f\"./images/{obj}/{id}.jpg\\n\")\n",
    "    # add all of the background data\n",
    "    for id in ids_background:\n",
    "        obj = id_to_name[id + \".jpg\"].split(\"/\")[0]\n",
    "        train_list.append(f\"./images/{obj}/{id}.jpg\\n\")\n",
    "    # add {multiplier} percentatge of the generated data\n",
    "    for obj in objs:\n",
    "        no_promopt_keys = unsuitable_prompts[obj]\n",
    "        # performance filter\n",
    "        if obj not in include_objs:\n",
    "            continue\n",
    "        ids_gen_obj = [\n",
    "            id\n",
    "            for id in ids_gen\n",
    "            if id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \") == obj\n",
    "        ]\n",
    "        ids_gen_obj_filtered = []\n",
    "        for id in ids_gen_obj:\n",
    "            # prompt filter\n",
    "            orig_stem = id_to_name_gen[id + \".jpg\"].split(\"/\")[-1]\n",
    "            if any([key in orig_stem for key in no_promopt_keys]):\n",
    "                continue\n",
    "            # lmm filter\n",
    "            if id in no_lmm:\n",
    "                continue\n",
    "            ids_gen_obj_filtered.append(id)\n",
    "        for id in ids_gen_obj_filtered:\n",
    "            obj = id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \")\n",
    "            train_list.append(f\"./generated_data/{obj}/{id}.jpg\\n\")\n",
    "    # save\n",
    "    shutil.copy(test_txt, yolo_filter_dir / test_txt.name)\n",
    "    with open(yolo_filter_dir / test_txt.name.replace(\"test\", \"trainval\"), \"w\") as f:\n",
    "        f.writelines([f\"{line}\" for line in train_list])\n",
    "\n",
    "print(f\"for {test_txt.name}\")\n",
    "print(f\"training dataset size: {len(train_list)} images\")\n",
    "print(f\"from which {sum(quota.values())} images are generated data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with multipliers\n",
    "\n",
    "multipliers = [0.1,0.25,0.5,0.75] corrsponds to generated-to-original data ratio [0.5:1,1:1,2:1,3:1] in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the quota for all filters but without multiplier as the baseline\n",
    "quota_base = quota\n",
    "\n",
    "# shuffle the ids_gen\n",
    "# TODO: a better way to sample data\n",
    "ids_gen_list = list(ids_gen)\n",
    "random.shuffle(ids_gen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for test.txt\n",
      "training dataset size: 49164 images\n",
      "from which 36860 images are generated data\n"
     ]
    }
   ],
   "source": [
    "# training set composition:\n",
    "# rest of the original data, all of the background data, and {multiplier} percentatge of the generated data\n",
    "# use {multiplier} percentatge of the data for training for each obj\n",
    "multipliers = [0.1, 0.25, 0.5, 0.75]\n",
    "# corrsponds to generated-to-original data ratio [0.5:1,1:1,2:1,3:1] in the paper\n",
    "\n",
    "for multiplier in multipliers:\n",
    "    yolo_filter_multiplier_dir = (\n",
    "        dataset_dir / f\"yolo_filter_{multiplier}\"\n",
    "    )  # TODO: change the name\n",
    "    # resume\n",
    "    if yolo_filter_multiplier_dir.exists():\n",
    "        print(f\"skipped {yolo_filter_multiplier_dir} since it already exists\")\n",
    "        continue\n",
    "    yolo_filter_multiplier_dir.mkdir(exist_ok=True)\n",
    "    os.symlink(\n",
    "        image_dir, yolo_filter_multiplier_dir / \"images\", target_is_directory=True\n",
    "    )\n",
    "    os.symlink(\n",
    "        generated_data_dir,\n",
    "        yolo_filter_multiplier_dir / \"generated_data\",\n",
    "        target_is_directory=True,\n",
    "    )\n",
    "    os.symlink(\n",
    "        yolo_all_dir / \"labels\",\n",
    "        yolo_filter_multiplier_dir / \"labels\",\n",
    "        target_is_directory=True,\n",
    "    )\n",
    "\n",
    "    quota = {obj: 0 for obj in objs}\n",
    "    for id in ids_gen_list:\n",
    "        obj = id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \")\n",
    "        orig_stem = id_to_name_gen[id + \".jpg\"].split(\"/\")[-1]\n",
    "        # multiplier\n",
    "        if quota[obj] >= quota_base[obj] * multiplier:\n",
    "            continue\n",
    "        # performance filter\n",
    "        if obj not in include_objs:\n",
    "            continue\n",
    "        # prompt filter\n",
    "        no_promopt_keys = unsuitable_prompts[obj]\n",
    "        if any([key in orig_stem for key in no_promopt_keys]):\n",
    "            continue\n",
    "        # lmm filter\n",
    "        if id in no_lmm:\n",
    "            continue\n",
    "        quota[obj] += 1\n",
    "\n",
    "    # for test_txt in yolo_dir.iterdir():\n",
    "    for txt_name in txt_names:\n",
    "        test_txt = yolo_dir / txt_name\n",
    "        with open(test_txt, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        test_ids_orig = set([line.split(\"/\")[-1].split(\".\")[0] for line in lines])\n",
    "        # TODO: do not consider val for now\n",
    "        train_ids_orig = ids_orig - test_ids_orig\n",
    "        train_list = []\n",
    "        # add rest of the original data\n",
    "        for id in train_ids_orig:\n",
    "            obj = id_to_name[id + \".jpg\"].split(\"/\")[0]\n",
    "            train_list.append(f\"./images/{obj}/{id}.jpg\\n\")\n",
    "        # add all of the background data\n",
    "        for id in ids_background:\n",
    "            obj = id_to_name[id + \".jpg\"].split(\"/\")[0]\n",
    "            train_list.append(f\"./images/{obj}/{id}.jpg\\n\")\n",
    "        # add {multiplier} percentatge of the generated data\n",
    "        for obj in objs:\n",
    "            # performance filter\n",
    "            if obj not in include_objs:\n",
    "                continue\n",
    "            ids_gen_obj = [\n",
    "                id\n",
    "                for id in ids_gen\n",
    "                if id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \") == obj\n",
    "            ]\n",
    "            ids_gen_obj_filtered = []\n",
    "            for id in ids_gen_obj:\n",
    "                # prompt filter\n",
    "                orig_stem = id_to_name_gen[id + \".jpg\"].split(\"/\")[-1]\n",
    "                if any([key in orig_stem for key in no_promopt_keys]):\n",
    "                    continue\n",
    "                # lmm filter\n",
    "                if id in no_lmm:\n",
    "                    continue\n",
    "                ids_gen_obj_filtered.append(id)\n",
    "            random.seed(SEED)\n",
    "            ids_gen_obj_sampled = random.sample(ids_gen_obj_filtered, quota[obj])\n",
    "            for id in ids_gen_obj_sampled:\n",
    "                obj = id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \")\n",
    "                train_list.append(f\"./generated_data/{obj}/{id}.jpg\\n\")\n",
    "        # save\n",
    "        shutil.copy(test_txt, yolo_filter_multiplier_dir / test_txt.name)\n",
    "        with open(\n",
    "            yolo_filter_multiplier_dir / test_txt.name.replace(\"test\", \"trainval\"), \"w\"\n",
    "        ) as f:\n",
    "            f.writelines([f\"{line}\" for line in train_list])\n",
    "\n",
    "print(f\"for {test_txt.name}\")\n",
    "print(f\"training dataset size: {len(train_list)} images\")\n",
    "print(f\"from which {sum(quota.values())} images are generated data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only gen\n",
    "\n",
    "no original images\n",
    "\n",
    "no performance filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'articulated dump truck': 957,\n",
       " 'bulldozer': 3805,\n",
       " 'combined piling and drilling rig': 2877,\n",
       " 'crawler crane': 3834,\n",
       " 'crawler excavator': 1440,\n",
       " 'crawler loader': 1885,\n",
       " 'duty cycle crane': 2785,\n",
       " 'gantry crane': 2460,\n",
       " 'log loader': 4796,\n",
       " 'maritime crane': 2999,\n",
       " 'material handling machine': 3838,\n",
       " 'mining bulldozer': 3752,\n",
       " 'mining excavator': 2704,\n",
       " 'mining truck': 1920,\n",
       " 'mobile crane': 1816,\n",
       " 'pipelayer': 1401,\n",
       " 'pontoon excavator': 1629,\n",
       " 'reachstacker': 931,\n",
       " 'telescopic handler': 4775,\n",
       " 'tower crane': 2680,\n",
       " 'truck mixer': 3835,\n",
       " 'wheel excavator': 2880,\n",
       " 'wheel loader': 1920}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter 0: get rid of the images with no annotations\n",
    "ids_gen = set(labels_nms_gen.keys()) - set(no_ann_gen)\n",
    "ids_orig = set(labels_nms_orig.keys()) - set(no_ann_orig)\n",
    "ids_background = set(labels_nms_background.keys()) - set(no_ann_background)\n",
    "\n",
    "quota = {obj: 0 for obj in objs}\n",
    "for id in ids_gen:\n",
    "    obj = id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \")\n",
    "    orig_stem = id_to_name_gen[id + \".jpg\"].split(\"/\")[-1]\n",
    "    # no performance filter\n",
    "    # prompt filter\n",
    "    no_promopt_keys = unsuitable_prompts[obj]\n",
    "    if any([key in orig_stem for key in no_promopt_keys]):\n",
    "        continue\n",
    "    # lmm filter\n",
    "    if id in no_lmm:\n",
    "        continue\n",
    "    quota[obj] += 1\n",
    "quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61919"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(quota.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with multipliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the quota for all filters but without multiplier as the baseline\n",
    "quota_base = quota\n",
    "\n",
    "# shuffle the ids_gen\n",
    "# TODO: a better way to sample data\n",
    "ids_gen_list = list(ids_gen)\n",
    "random.shuffle(ids_gen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for test.txt\n",
      "training dataset size: 61961 images\n",
      "from which 61919 images are generated data\n"
     ]
    }
   ],
   "source": [
    "# training set composition:\n",
    "# rest of the original data, all of the background data, and {multiplier} percentatge of the generated data\n",
    "# use {multiplier} percentatge of the data for training for each obj\n",
    "multipliers = [0.2, 1.0]  # 0.2 corresponds to 1:0 ratio in the paper\n",
    "\n",
    "for multiplier in multipliers:\n",
    "    yolo_filter_multiplier_dir = (\n",
    "        dataset_dir / f\"yolo_gen_{multiplier}\"\n",
    "    )  # TODO: change the name\n",
    "    # resume\n",
    "    if yolo_filter_multiplier_dir.exists():\n",
    "        print(f\"skipped {yolo_filter_multiplier_dir} since it already exists\")\n",
    "        continue\n",
    "    yolo_filter_multiplier_dir.mkdir(exist_ok=True)\n",
    "    os.symlink(\n",
    "        image_dir, yolo_filter_multiplier_dir / \"images\", target_is_directory=True\n",
    "    )\n",
    "    os.symlink(\n",
    "        generated_data_dir,\n",
    "        yolo_filter_multiplier_dir / \"generated_data\",\n",
    "        target_is_directory=True,\n",
    "    )\n",
    "    os.symlink(\n",
    "        yolo_all_dir / \"labels\",\n",
    "        yolo_filter_multiplier_dir / \"labels\",\n",
    "        target_is_directory=True,\n",
    "    )\n",
    "\n",
    "    quota = {obj: 0 for obj in objs}\n",
    "    for id in ids_gen_list:\n",
    "        obj = id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \")\n",
    "        orig_stem = id_to_name_gen[id + \".jpg\"].split(\"/\")[-1]\n",
    "        # multiplier\n",
    "        if quota[obj] >= quota_base[obj] * multiplier:\n",
    "            continue\n",
    "        # # performance filter\n",
    "        # if obj not in include_objs:\n",
    "        #     continue\n",
    "        # prompt filter\n",
    "        no_promopt_keys = unsuitable_prompts[obj]\n",
    "        if any([key in orig_stem for key in no_promopt_keys]):\n",
    "            continue\n",
    "        # lmm filter\n",
    "        if id in no_lmm:\n",
    "            continue\n",
    "        quota[obj] += 1\n",
    "\n",
    "    # for test_txt in yolo_dir.iterdir():\n",
    "    for txt_name in txt_names:\n",
    "        if \"gpt\" in txt_name:  # no original data, so no gpt\n",
    "            continue\n",
    "        test_txt = yolo_dir / txt_name\n",
    "\n",
    "        with open(test_txt, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        test_ids_orig = set([line.split(\"/\")[-1].split(\".\")[0] for line in lines])\n",
    "        # TODO: do not consider val for now\n",
    "        # train_ids_orig = ids_orig - test_ids_orig\n",
    "        train_list = []\n",
    "        # # add rest of the original data\n",
    "        # for id in train_ids_orig:\n",
    "        #     obj = id_to_name[id+'.jpg'].split('/')[0]\n",
    "        #     train_list.append(f\"./images/{obj}/{id}.jpg\\n\")\n",
    "        # add all of the background data\n",
    "        for id in ids_background:\n",
    "            obj = id_to_name[id + \".jpg\"].split(\"/\")[0]\n",
    "            train_list.append(f\"./images/{obj}/{id}.jpg\\n\")\n",
    "        # add {multiplier} percentatge of the generated data\n",
    "        for obj in objs:\n",
    "            # # performance filter\n",
    "            # if obj not in include_objs:\n",
    "            #     continue\n",
    "            ids_gen_obj = [\n",
    "                id\n",
    "                for id in ids_gen\n",
    "                if id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \") == obj\n",
    "            ]\n",
    "            ids_gen_obj_filtered = []\n",
    "            for id in ids_gen_obj:\n",
    "                # prompt filter\n",
    "                orig_stem = id_to_name_gen[id + \".jpg\"].split(\"/\")[-1]\n",
    "                if any([key in orig_stem for key in no_promopt_keys]):\n",
    "                    continue\n",
    "                # lmm filter\n",
    "                if id in no_lmm:\n",
    "                    continue\n",
    "                ids_gen_obj_filtered.append(id)\n",
    "            random.seed(SEED)\n",
    "            ids_gen_obj_sampled = random.sample(ids_gen_obj_filtered, quota[obj])\n",
    "            for id in ids_gen_obj_sampled:\n",
    "                obj = id_to_name_gen[id + \".jpg\"].split(\"/\")[1].replace(\"_\", \" \")\n",
    "                train_list.append(f\"./generated_data/{obj}/{id}.jpg\\n\")\n",
    "        # save\n",
    "        shutil.copy(test_txt, yolo_filter_multiplier_dir / test_txt.name)\n",
    "        with open(\n",
    "            yolo_filter_multiplier_dir / test_txt.name.replace(\"test\", \"trainval\"), \"w\"\n",
    "        ) as f:\n",
    "            f.writelines([f\"{line}\" for line in train_list])\n",
    "\n",
    "print(f\"for {test_txt.name}\")\n",
    "print(f\"training dataset size: {len(train_list)} images\")\n",
    "print(f\"from which {sum(quota.values())} images are generated data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
