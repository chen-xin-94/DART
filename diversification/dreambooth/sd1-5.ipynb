{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"/mnt/ssd2/xin/repo/DART/Liebherr_Product\")\n",
    "repo_dir = Path(\"/mnt/ssd2/xin/repo/DART/diversification\")\n",
    "diffusers_dir = Path(\"/mnt/ssd2/xin/repo/diffusers\")\n",
    "\n",
    "MODEL_NAME = \"sd1-5\"\n",
    "\n",
    "class_data_dir = repo_dir / \"dreambooth\" / \"class_data\" / MODEL_NAME\n",
    "instance_data_dir = repo_dir / \"instance_data\"\n",
    "script_dir = repo_dir / \"dreambooth\" / \"scripts\" / MODEL_NAME\n",
    "script_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(obj, placeholder_token, plural=False, naive=False):\n",
    "\n",
    "    if naive:\n",
    "        return f\"A photo of {placeholder_token} {obj}(s) on a construction site.\"\n",
    "    else:\n",
    "        if plural:\n",
    "            return f\"A photo of {placeholder_token} {obj}(s) on a construction site. The image is high quality and photorealistic, with one or several {placeholder_token} {obj}s visible from various angles and distances. The {placeholder_token} {obj}s may be partially visible, at a distance, or obscured, ensuring a variety of training examples for object detection. The background is complex, providing a realistic context.\"\n",
    "        else:\n",
    "            return f\"A photo of a {placeholder_token} {obj} on a construction site. The image is high quality and photorealistic. The {placeholder_token} {obj} may be partially visible, at a distance, or obscured, ensuring a variety of training examples for object detection. The background is complex, providing a realistic context.\"\n",
    "\n",
    "\n",
    "def get_unique_path(folder, base_name):\n",
    "    base_path = Path(folder) / base_name\n",
    "    counter = 1\n",
    "    cur_path = base_path\n",
    "\n",
    "    while cur_path.exists():\n",
    "        cur_path = base_path.parent / f\"{base_path.stem}_{counter}{base_path.suffix}\"\n",
    "        counter += 1\n",
    "\n",
    "    return cur_path\n",
    "\n",
    "\n",
    "def process_variables(\n",
    "    obj,\n",
    "    instance,\n",
    "    repo_dir,\n",
    "    hyperparameters,\n",
    "    placeholder_token=\"sks\",\n",
    "    acc_config=\"default_config\",\n",
    "    report_to=\"wandb\",\n",
    "):\n",
    "    # Process the variables based on obj and repo_dir\n",
    "    obj_ = obj.replace(\" \", \"_\")\n",
    "    model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "    obj_instance_data_dir = instance_data_dir / obj_ / instance\n",
    "    script_path = get_unique_path(\n",
    "        repo_dir / \"dreambooth\" / \"scripts\" / MODEL_NAME / obj_, instance + \".sh\"\n",
    "    )\n",
    "    output_dir = Path(str(script_path).replace(\"scripts\", \"output\").replace(\".sh\", \"\"))\n",
    "\n",
    "    # whether to use instance-level or class-level data for class data generation\n",
    "    if instance[0].islower():\n",
    "        # if the instance is not capitalized, the instance name is supposed to be a subclass name with semantic meaning\n",
    "        class_prompt = f\"a photo of a {instance.replace('_',' ')} {obj}\"\n",
    "        obj_class_data_dir = class_data_dir / obj_ / instance\n",
    "\n",
    "    elif instance[0].isupper() or instance.isdigit():\n",
    "        class_prompt = f\"a photo of {obj}\"\n",
    "        obj_class_data_dir = class_data_dir / obj_\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Instance name should either be a model name (i.e. start with a capital letter or a digit) or a subclass name (i.e. start with a lowercase letter)\"\n",
    "        )\n",
    "\n",
    "    # set max training steps to #images*120\n",
    "    num_instance_images = len(list(obj_instance_data_dir.glob(\"*.jpg\")))\n",
    "    max_train_steps = max(num_instance_images * 120, 800)\n",
    "\n",
    "    return {\n",
    "        \"max_train_steps\": max_train_steps,\n",
    "        \"model_name\": model_name,\n",
    "        \"instance_data_dir\": str(obj_instance_data_dir),\n",
    "        \"output_dir\": str(output_dir),\n",
    "        \"script_path\": str(script_path),\n",
    "        \"class_data_dir\": str(obj_class_data_dir),\n",
    "        \"instance_prompt\": f\"a photo of a {placeholder_token} {obj}\",\n",
    "        \"class_prompt\": class_prompt,\n",
    "        \"validation_prompt\": get_prompt(\n",
    "            obj, placeholder_token, plural=False, naive=False\n",
    "        ),\n",
    "        \"acc_config_path\": Path.home()\n",
    "        / \".cache/huggingface/accelerate\"\n",
    "        / (str(acc_config) + \".yaml\"),\n",
    "        \"report_to\": report_to,\n",
    "        **hyperparameters.__dict__,\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_variables(variables):\n",
    "    command = f\"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "cd {diffusers_dir}/examples/dreambooth\n",
    "\n",
    "export MODEL_NAME=\"{variables['model_name']}\"\n",
    "export INSTANCE_DATA_DIR=\"{variables['instance_data_dir']}\"\n",
    "export OUTPUT_DIR=\"{variables['output_dir']}\"\n",
    "export CLASS_DATA_DIR=\"{variables['class_data_dir']}\"\n",
    "export CONFIG_FILE=\"{variables['acc_config_path']}\"\n",
    "\n",
    "accelerate launch --config_file=$CONFIG_FILE\\\\\n",
    "  train_dreambooth.py \\\\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\\\n",
    "  --instance_data_dir=$INSTANCE_DATA_DIR \\\\\n",
    "  --output_dir=$OUTPUT_DIR \\\\\n",
    "  --instance_prompt=\"{variables['instance_prompt']}\" \\\\\n",
    "  --resolution={variables['resolution']} \\\\\n",
    "  --train_batch_size={variables['train_batch_size']} \\\\\n",
    "  --gradient_accumulation_steps={variables['gradient_accumulation_steps']} \\\\\n",
    "  --learning_rate={variables['learning_rate']} \\\\\n",
    "  --lr_scheduler=\"{variables['lr_scheduler']}\" \\\\\n",
    "  --lr_warmup_steps={variables['lr_warmup_steps']} \\\\\n",
    "  --max_train_steps={variables['max_train_steps']} \\\\\n",
    "  --checkpointing_steps={variables['checkpointing_steps']} \\\\\n",
    "  --mixed_precision=\"{variables['mixed_precision']}\" \\\\\n",
    "  --prior_loss_weight={variables['prior_loss_weight']} \\\\\n",
    "  --num_validation_images={variables['num_validation_images']} \\\\\n",
    "\"\"\"\n",
    "\n",
    "    validation_steps = variables.get(\"validation_steps\", None)\n",
    "    validation_epochs = variables.get(\"validation_epochs\", None)\n",
    "    if validation_steps:\n",
    "        command += f\"  --validation_steps={validation_steps} \\\\\\n\"\n",
    "        command += f\"  --validation_prompt=\\\"{variables['validation_prompt']}\\\"\\n\"\n",
    "    if validation_epochs:\n",
    "        command += f\"  --validation_epochs={validation_epochs} \\\\\\n\"\n",
    "        command += f\"  --validation_prompt=\\\"{variables['validation_prompt']}\\\"\\n\"\n",
    "\n",
    "    if variables[\"with_prior_preservation\"]:\n",
    "        command = command.rstrip() + \" \\\\\\n\"  # replace \\n with \\\\\\n\n",
    "\n",
    "        command += f\"  --with_prior_preservation \\\\\\n\"\n",
    "\n",
    "        command += f\"  --class_data_dir=$CLASS_DATA_DIR \\\\\\n\"\n",
    "        command += f\"  --class_prompt=\\\"{variables['class_prompt']}\\\" \\n\"\n",
    "\n",
    "    if variables.get(\"snr_gamma\", None):\n",
    "        command = command.rstrip() + \" \\\\\\n\"\n",
    "        command += f\"  --snr_gamma={variables['snr_gamma']}\\n\"\n",
    "\n",
    "    if variables.get(\"do_edm_style_training\", None):\n",
    "        command = command.rstrip() + \" \\\\\\n\"\n",
    "        command += f\"  --do_edm_style_training\\n\"\n",
    "\n",
    "    if variables.get(\"train_text_encoder\", None):\n",
    "        command = command.rstrip() + \" \\\\\\n\"\n",
    "        command += f\"  --train_text_encoder\\n\"\n",
    "\n",
    "    if variables.get(\"report_to\", None):\n",
    "        command = command.rstrip() + \" \\\\\\n\"\n",
    "        command += f'  --report_to=\"{variables[\"report_to\"]}\"\\n'\n",
    "\n",
    "    return command\n",
    "\n",
    "\n",
    "def generate_command(\n",
    "    placeholder_token, obj, instance, acc_config, report_to, hyperparameters\n",
    "):\n",
    "    variables = process_variables(\n",
    "        obj,\n",
    "        instance,\n",
    "        repo_dir,\n",
    "        hyperparameters,\n",
    "        placeholder_token,\n",
    "        acc_config,\n",
    "        report_to,\n",
    "    )\n",
    "    command = parse_variables(variables)\n",
    "    return command, variables\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Hyperparameters:\n",
    "    resolution: int = 512\n",
    "    train_batch_size: int = 1\n",
    "    gradient_accumulation_steps: int = 1\n",
    "    learning_rate: float = 5e-6\n",
    "    lr_scheduler: str = \"constant\"\n",
    "    lr_warmup_steps: int = 0\n",
    "    # max_train_steps: int = 1200 # max_train_steps is set to #images*120 in process_variables\n",
    "    checkpointing_steps: int = 500\n",
    "    # validation_epochs: int = 50\n",
    "    validation_steps: int = 500\n",
    "    mixed_precision: str = \"bf16\"\n",
    "    with_prior_preservation: bool = True\n",
    "    prior_loss_weight: float = 1.0\n",
    "    num_validation_images: int = 4\n",
    "    train_text_encoder: bool = False\n",
    "    snr_gamma: float = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#!/bin/bash\n",
      "\n",
      "cd /mnt/ssd2/xin/repo/diffusers/examples/dreambooth\n",
      "\n",
      "export MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
      "export INSTANCE_DATA_DIR=\"/mnt/ssd2/xin/repo/DART/diversification/instance_data/articulated_dump_truck/TA230\"\n",
      "export OUTPUT_DIR=\"/mnt/ssd2/xin/repo/DART/diversification/dreambooth/output/sd1-5/articulated_dump_truck/TA230_1\"\n",
      "export CLASS_DATA_DIR=\"/mnt/ssd2/xin/repo/DART/diversification/dreambooth/class_data/sd1-5/articulated_dump_truck\"\n",
      "export CONFIG_FILE=\"/home/chenxin/.cache/huggingface/accelerate/default_config.yaml\"\n",
      "\n",
      "accelerate launch --config_file=$CONFIG_FILE\\\n",
      "  train_dreambooth.py \\\n",
      "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
      "  --instance_data_dir=$INSTANCE_DATA_DIR \\\n",
      "  --output_dir=$OUTPUT_DIR \\\n",
      "  --instance_prompt=\"a photo of a <TA230> articulated dump truck\" \\\n",
      "  --resolution=512 \\\n",
      "  --train_batch_size=1 \\\n",
      "  --gradient_accumulation_steps=1 \\\n",
      "  --learning_rate=5e-06 \\\n",
      "  --lr_scheduler=\"constant\" \\\n",
      "  --lr_warmup_steps=0 \\\n",
      "  --max_train_steps=1200 \\\n",
      "  --checkpointing_steps=500 \\\n",
      "  --mixed_precision=\"bf16\" \\\n",
      "  --prior_loss_weight=1.0 \\\n",
      "  --num_validation_images=4 \\\n",
      "  --validation_steps=500 \\\n",
      "  --validation_prompt=\"A photo of a <TA230> articulated dump truck on a construction site. The image is high quality and photorealistic. The <TA230> articulated dump truck may be partially visible, at a distance, or obscured, ensuring a variety of training examples for object detection. The background is complex, providing a realistic context.\" \\\n",
      "  --with_prior_preservation \\\n",
      "  --class_data_dir=$CLASS_DATA_DIR \\\n",
      "  --class_prompt=\"a photo of articulated dump truck\" \\\n",
      "  --snr_gamma=5.0 \\\n",
      "  --report_to=\"wandb\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obj = \"articulated dump truck\"\n",
    "instance = \"TA230\"\n",
    "placeholder_token = f\"<{instance}>\"\n",
    "\n",
    "acc_config = \"default_config\"  # device\n",
    "report_to = \"wandb\"\n",
    "hyperparameters = Hyperparameters()\n",
    "\n",
    "command, variables = generate_command(\n",
    "    placeholder_token, obj, instance, acc_config, report_to, hyperparameters\n",
    ")\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script saved at \n",
      "/mnt/ssd2/xin/repo/DART/diversification/dreambooth/scripts/sd1-5/articulated_dump_truck/TA230_1.sh\n"
     ]
    }
   ],
   "source": [
    "# save the script\n",
    "obj_ = obj.replace(\" \", \"_\")\n",
    "script_path = script_dir / f\"{get_unique_path(script_dir/obj_,instance+'.sh')}\"\n",
    "script_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(command)\n",
    "print(f\"Script saved at \\n{script_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
